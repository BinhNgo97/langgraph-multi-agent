"""
Streamlit UI cho LangGraph Multi-Agent System
"""

import streamlit as st
from graph.builder import build_graph
from config.settings import settings
import os

# Page config
st.set_page_config(
    page_title="LangGraph Multi-Agent System",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .agent-box {
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .solver-box {
        background-color: #e3f2fd;
        border-left: 4px solid #2196f3;
    }
    .critic-box {
        background-color: #fff3e0;
        border-left: 4px solid #ff9800;
    }
    .alternative-box {
        background-color: #f3e5f5;
        border-left: 4px solid #9c27b0;
    }
    .judge-box {
        background-color: #e8f5e9;
        border-left: 4px solid #4caf50;
    }
</style>
""", unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.title("‚öôÔ∏è C·∫•u h√¨nh")
    
    # API Key
    api_key = st.text_input(
        "OpenAI API Key",
        value=settings.openai_api_key or "",
        type="password",
        help="Nh·∫≠p OpenAI API key c·ªßa b·∫°n"
    )
    
    if api_key:
        settings.openai_api_key = api_key
        os.environ["OPENAI_API_KEY"] = api_key
    
    st.divider()
    
    # Model settings
    st.markdown("### ü§ñ Model chung")
    model_name = st.selectbox(
        "Model m·∫∑c ƒë·ªãnh",
        ["gpt-4o-mini", "gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo"],
        index=0,
        help="Model m·∫∑c ƒë·ªãnh cho t·∫•t c·∫£ agents"
    )
    settings.model_name = model_name
    
    temperature = st.slider(
        "Temperature",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1,
        help="ƒê·ªô s√°ng t·∫°o c·ªßa AI (0=ch√≠nh x√°c, 1=s√°ng t·∫°o)"
    )
    settings.temperature = temperature
    
    st.divider()
    
    # Agent-specific models
    st.markdown("### üéØ Model cho t·ª´ng Agent")
    
    with st.expander("‚öôÔ∏è T√πy ch·ªânh model cho t·ª´ng agent", expanded=False):
        st.markdown("*ƒê·ªÉ tr·ªëng ƒë·ªÉ d√πng model m·∫∑c ƒë·ªãnh*")
        
        # Available models
        openai_models = ["gpt-4o-mini", "gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo"]
        claude_models = ["claude-3-5-sonnet-20241022", "claude-3-opus-20240229"]
        all_models = [""] + openai_models + claude_models
        
        # Input Normalizer
        normalizer_model = st.selectbox(
            "üîç Input Normalizer",
            all_models,
            index=0,
            help="Model ph√¢n t√≠ch v·∫•n ƒë·ªÅ ƒë·∫ßu v√†o"
        )
        if normalizer_model:
            settings.agent_models["input_normalizer"] = normalizer_model
        
        # Proposer
        proposer_model = st.selectbox(
            "üîµ Proposer (AI #1)",
            all_models,
            index=0,
            help="Model ƒë·ªÅ xu·∫•t gi·∫£i ph√°p"
        )
        if proposer_model:
            settings.agent_models["proposer"] = proposer_model
        
        # Critic
        critic_model = st.selectbox(
            "üü† Critic (AI #2)",
            all_models,
            index=all_models.index("gpt-4o") if "gpt-4o" in all_models else 0,
            help="Model ph·∫£n bi·ªán (n√™n d√πng model m·∫°nh)"
        )
        if critic_model:
            settings.agent_models["critic"] = critic_model
        
        # Challenger
        challenger_model = st.selectbox(
            "üü£ Challenger (AI #3)",
            all_models,
            index=all_models.index("claude-3-5-sonnet-20241022") if settings.anthropic_api_key else 0,
            help="Model t√¨m ph·∫£n v√≠ d·ª• (khuy√™n d√πng Claude)"
        )
        if challenger_model:
            settings.agent_models["challenger"] = challenger_model
        
        # Synthesizer
        synthesizer_model = st.selectbox(
            "üü¢ Synthesizer (AI #4)",
            all_models,
            index=all_models.index("gpt-4o") if "gpt-4o" in all_models else 0,
            help="Model t·ªïng h·ª£p (n√™n d√πng model m·∫°nh)"
        )
        if synthesizer_model:
            settings.agent_models["synthesizer"] = synthesizer_model
        
        # Hi·ªÉn th·ªã c·∫•u h√¨nh hi·ªán t·∫°i
        st.markdown("---")
        st.markdown("**C·∫•u h√¨nh hi·ªán t·∫°i:**")
        for agent, model in settings.agent_models.items():
            provider = "üü¶ OpenAI" if "gpt" in model.lower() else "üü£ Anthropic"
            st.text(f"{agent}: {model} ({provider})")
    
    max_iterations = st.slider(
        "S·ªë v√≤ng l·∫∑p t·ªëi ƒëa",
        min_value=1,
        max_value=10,
        value=5,
        help="S·ªë l·∫ßn t·ªëi ƒëa c√°c agents tranh lu·∫≠n"
    )
    settings.max_iterations = max_iterations
    
    st.divider()
    
    # Info
    st.markdown("### üìä Th√¥ng tin")
    
    # Hi·ªÉn th·ªã models ƒëang d√πng
    st.info(f"""
    **Model m·∫∑c ƒë·ªãnh:** {model_name}  
    **Temperature:** {temperature}  
    **Max iterations:** {max_iterations}
    
    **Agent Models:**
    - Normalizer: {settings.agent_models.get('input_normalizer', 'default')}
    - Proposer: {settings.agent_models.get('proposer', 'default')}
    - Critic: {settings.agent_models.get('critic', 'default')}
    - Challenger: {settings.agent_models.get('challenger', 'default')}
    - Synthesizer: {settings.agent_models.get('synthesizer', 'default')}
    """)
    
    # Reset button
    if st.button("üîÑ Reset Chat", use_container_width=True):
        st.session_state.messages = []
        st.session_state.history = []
        st.rerun()

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "history" not in st.session_state:
    st.session_state.history = []

# Main header
st.markdown('<div class="main-header">ü§ñ H·ªÜ TH·ªêNG AI ƒêA T√ÅC T·ª¨</div>', unsafe_allow_html=True)
st.markdown("### T√¨m gi·∫£i ph√°p t·ªëi ∆∞u th√¥ng qua ph·∫£n bi·ªán v√† tranh lu·∫≠n")
st.divider()

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Chat input
if prompt := st.chat_input("Nh·∫≠p v·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt..."):
    # Check API key
    if not settings.openai_api_key:
        st.error("‚ö†Ô∏è Vui l√≤ng nh·∫≠p OpenAI API Key ·ªü sidebar!")
        st.stop()
    
    # Add user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Process with LangGraph
    with st.chat_message("assistant"):
        with st.spinner("ü§î ƒêang ph√¢n t√≠ch v·∫•n ƒë·ªÅ..."):
            try:
                # Build graph
                app = build_graph()
                
                # Initial state
                initial_state = {
                    "raw_problem": prompt,
                    "problem": "",
                    "context": "",
                    "proposer_solution": "",
                    "critic_feedback": "",
                    "challenger_counterexample": "",
                    "synthesizer_result": "",
                    "final_decision": "",
                    "final_reasoning": "",
                    "key_points": {},
                    "iteration": 0,
                    "quality_score": 0.0,
                    "should_continue": True,
                    "messages": []
                }
                
                # Create containers for each agent
                normalizer_container = st.container()
                proposer_container = st.container()
                critic_container = st.container()
                challenger_container = st.container()
                synthesizer_container = st.container()
                final_container = st.container()
                
                # Run graph
                result = None
                current_iteration = 0
                for node_output in app.stream(initial_state):
                    node_name = list(node_output.keys())[0]
                    node_output = node_output[node_name]
                    iteration = node_output.get("iteration", 0)
                    
                    if node_name == "input_normalizer":
                        with normalizer_container:
                            st.markdown(f'<div class="agent-box solver-box">', unsafe_allow_html=True)
                            model_used = settings.agent_models.get("input_normalizer", "default")
                            st.markdown(f"**üîç Input Normalizer** ({model_used})")
                            st.markdown(node_output.get("problem", ""))
                            st.markdown('</div>', unsafe_allow_html=True)
                    
                    elif node_name == "proposer":
                        with proposer_container:
                            st.markdown(f'<div class="agent-box solver-box">', unsafe_allow_html=True)
                            model_used = settings.agent_models.get("proposer", "default")
                            st.markdown(f"**üîµ AI #1: Proposer** - V√≤ng {iteration} ({model_used})")
                            st.markdown(node_output.get("proposer_solution", ""))
                            st.markdown('</div>', unsafe_allow_html=True)
                    
                    elif node_name == "critic":
                        with critic_container:
                            st.markdown(f'<div class="agent-box critic-box">', unsafe_allow_html=True)
                            model_used = settings.agent_models.get("critic", "default")
                            st.markdown(f"**üü† AI #2: Critic** - V√≤ng {iteration} ({model_used})")
                            st.markdown(node_output.get("critic_feedback", ""))
                            st.markdown('</div>', unsafe_allow_html=True)
                    
                    elif node_name == "challenger":
                        with challenger_container:
                            st.markdown(f'<div class="agent-box alternative-box">', unsafe_allow_html=True)
                            model_used = settings.agent_models.get("challenger", "default")
                            st.markdown(f"**üü£ AI #3: Challenger** - V√≤ng {iteration} ({model_used})")
                            st.markdown(node_output.get("challenger_counterexample", ""))
                            st.markdown('</div>', unsafe_allow_html=True)
                    
                    elif node_name == "synthesizer":
                        score = node_output.get("quality_score", 0)
                        with synthesizer_container:
                            st.markdown(f'<div class="agent-box judge-box">', unsafe_allow_html=True)
                            model_used = settings.agent_models.get("synthesizer", "default")
                            st.markdown(f"**üü¢ AI #4: Synthesizer** - V√≤ng {iteration} ({model_used}) - ƒêi·ªÉm: {score}/10")
                            st.markdown(node_output.get("synthesizer_result", ""))
                            st.markdown('</div>', unsafe_allow_html=True)
                        current_iteration = iteration
                    
                    elif node_name == "final_decision":
                        with final_container:
                            st.markdown(f'<div class="agent-box judge-box">', unsafe_allow_html=True)
                            st.markdown("**üéØ Final Decision - K·∫øt lu·∫≠n cu·ªëi c√πng**")
                            st.markdown(node_output.get("final_decision", ""))
                            st.markdown('</div>', unsafe_allow_html=True)
                        result = node_output
                
                # Summary
                if result:
                    st.divider()
                    st.success(f"‚úÖ Ho√†n th√†nh sau {current_iteration} v√≤ng l·∫∑p")
                    
                    # Save to history
                    st.session_state.history.append({
                        "problem": prompt,
                        "result": result.get("final_decision", ""),
                        "iterations": current_iteration
                    })
                    
                    # Add assistant message
                    response = f"""
**üéØ K·∫øt qu·∫£ cu·ªëi c√πng:**

{result.get("final_decision", "")}

---
*ƒê√£ ph√¢n t√≠ch qua {current_iteration} v√≤ng tranh lu·∫≠n*
"""
                    st.session_state.messages.append({"role": "assistant", "content": response})
            
            except Exception as e:
                st.error(f"‚ùå L·ªói: {str(e)}")
                import traceback
                with st.expander("Chi ti·∫øt l·ªói"):
                    st.code(traceback.format_exc())

# Show history in expander
if st.session_state.history:
    with st.expander(f"üìö L·ªãch s·ª≠ ({len(st.session_state.history)} c√¢u h·ªèi)"):
        for i, item in enumerate(reversed(st.session_state.history)):
            st.markdown(f"**{i+1}. {item['problem']}**")
            st.markdown(f"*S·ªë v√≤ng l·∫∑p: {item['iterations']}*")
            st.divider()
